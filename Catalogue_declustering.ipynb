{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valebl/SSZ_Clustering/blob/main/Catalogue_declustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhugslrKhbSw"
      },
      "source": [
        "# CATALOGUE DECLUSTERING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gSoVly9YzGJp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "from copy import deepcopy\n",
        "import seaborn as sns\n",
        "\n",
        "from utils import haversine_np, is_leap_year, date_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PATHS -> change if you need\n",
        "\n",
        "input_catalogue_path = \"/content/drive/MyDrive/SeismicSources/CATALOGUE.xlsx\"\n",
        "output_catalogue_path = \"/content/drive/MyDrive/SeismicSources/CPTI15_v3.0_declustered.xlsx\"\n",
        "\n",
        "# FLAGS\n",
        "\n",
        "write_csv = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qhZQNrIzKoj",
        "outputId": "4c01c740-0851-4fb7-9d88-3b84b3452aa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The database contains 4860 events\n",
            "\n",
            "After removing LatDef=NaN: 4748 events\n",
            "After removing also LonDef=NaN: 4748 events\n",
            "After removing also MwDef=NaN: 4703 events\n",
            "After removing also Year=NaN: 4703 events\n",
            "After removing also Mo=NaN: 4651 events\n",
            "After removing also Da=NaN: 4597 events\n",
            "\n",
            "    Year    Mo    Da    Ho  ...  DepDef  MwDef             X             Y\n",
            "2   1019   4.0   1.0   NaN  ...     NaN   4.63  9.850866e+05  4.569418e+06\n",
            "3   1044   4.0  19.0   9.0  ...     NaN   4.63  9.850866e+05  4.569418e+06\n",
            "5   1065   3.0  27.0   NaN  ...     NaN   5.10  5.952487e+05  5.043553e+06\n",
            "7   1087   9.0  10.0   NaN  ...     NaN   4.86  1.160782e+06  4.583025e+06\n",
            "8   1091   1.0  27.0   NaN  ...     NaN   5.10  7.884312e+05  4.644411e+06\n",
            "9   1094   1.0  14.0   NaN  ...     NaN   4.63  9.850866e+05  4.569418e+06\n",
            "10  1117   1.0   3.0  15.0  ...     NaN   6.52  6.580732e+05  5.014586e+06\n",
            "12  1120   3.0  25.0   NaN  ...     NaN   5.80  9.112262e+05  4.592288e+06\n",
            "13  1125   6.0   7.0  11.0  ...     NaN   5.80  1.059076e+06  4.121501e+06\n",
            "14  1125  10.0  11.0   NaN  ...     NaN   5.33  9.850866e+05  4.569418e+06\n",
            "\n",
            "[10 rows x 12 columns] \n",
            "\n",
            "Ho=Nan, Mi=NaN and Se=NaN are substituted with 0\n",
            "\n",
            "    Year    Mo    Da    Ho  ...  DepDef  MwDef             X             Y\n",
            "2   1019   4.0   1.0   0.0  ...     NaN   4.63  9.850866e+05  4.569418e+06\n",
            "3   1044   4.0  19.0   9.0  ...     NaN   4.63  9.850866e+05  4.569418e+06\n",
            "5   1065   3.0  27.0   0.0  ...     NaN   5.10  5.952487e+05  5.043553e+06\n",
            "7   1087   9.0  10.0   0.0  ...     NaN   4.86  1.160782e+06  4.583025e+06\n",
            "8   1091   1.0  27.0   0.0  ...     NaN   5.10  7.884312e+05  4.644411e+06\n",
            "9   1094   1.0  14.0   0.0  ...     NaN   4.63  9.850866e+05  4.569418e+06\n",
            "10  1117   1.0   3.0  15.0  ...     NaN   6.52  6.580732e+05  5.014586e+06\n",
            "12  1120   3.0  25.0   0.0  ...     NaN   5.80  9.112262e+05  4.592288e+06\n",
            "13  1125   6.0   7.0  11.0  ...     NaN   5.80  1.059076e+06  4.121501e+06\n",
            "14  1125  10.0  11.0   0.0  ...     NaN   5.33  9.850866e+05  4.569418e+06\n",
            "\n",
            "[10 rows x 12 columns] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_excel(input_catalogue_path, usecols=\"A:M\", engine=\"openpyxl\")\n",
        "df = df[['Year','Mo','Da','Ho','Mi','Se','LatDef','LonDef','DepDef','MwDef','X','Y']]\n",
        "\n",
        "print(f\"The database contains {len(df)} events\\n\")\n",
        "\n",
        "df = df[df['LatDef'].notna()]\n",
        "print(f\"After removing LatDef=NaN: {len(df)} events\")\n",
        "\n",
        "df = df[df['LonDef'].notna()]\n",
        "print(f\"After removing also LonDef=NaN: {len(df)} events\")\n",
        "\n",
        "df = df[df['MwDef'].notna()]\n",
        "print(f\"After removing also MwDef=NaN: {len(df)} events\")\n",
        "\n",
        "df = df[df['Year'].notna()]\n",
        "print(f\"After removing also Year=NaN: {len(df)} events\")\n",
        "\n",
        "df = df[df['Mo'].notna()]\n",
        "print(f\"After removing also Mo=NaN: {len(df)} events\")\n",
        "\n",
        "df = df[df['Da'].notna()]\n",
        "print(f\"After removing also Da=NaN: {len(df)} events\\n\")\n",
        "\n",
        "print(df.head(10), '\\n')\n",
        "\n",
        "print(f\"Ho=Nan, Mi=NaN and Se=NaN are substituted with 0\\n\")\n",
        "df[['Ho','Mi','Se']] = df[['Ho','Mi','Se']].replace([np.nan, \"NaN\"], 0)\n",
        "\n",
        "print(df.head(10), '\\n')\n",
        "\n",
        "\n",
        "# Write the dataframe object into csv file\n",
        "if write_csv:\n",
        "    df.to_csv (\"CPTI15_v3.0.csv\", header=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z-mZjAB8vko"
      },
      "source": [
        "## Declustering\n",
        "\n",
        "The script works on a dataframe structured as follows:\n",
        "\n",
        "Year  Month  Day  Hour  Minute  Second  Latitude  Longitude  Depth  Mw  X  Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OxouaCSpx3kP"
      },
      "outputs": [],
      "source": [
        "## Calculate the distance matrix\n",
        "LONG_ALL = df['LonDef'].values\n",
        "LAT_ALL = df['LatDef'].values\n",
        "\n",
        "DISTANCES = [haversine_np(lon, lat, LONG_ALL, LAT_ALL) for lon, lat in zip(LONG_ALL,LAT_ALL)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejtrnZnbyAMo",
        "outputId": "0f677bbb-f9b3-42e9-dc5d-00c16ac13d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4597\n"
          ]
        }
      ],
      "source": [
        "print(len(DISTANCES[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r-zzEvzv87u",
        "outputId": "564be28b-d05e-411a-b1e6-6a145a8170bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[  0.           0.         612.69046636 ... 426.61215296   6.57567579\n",
            " 365.54154433]\n"
          ]
        }
      ],
      "source": [
        "print(DISTANCES[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaPs9jkTDX8f",
        "outputId": "0e7bef6d-efb2-4dbc-e278-5e1246d8cbb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: RuntimeWarning: overflow encountered in exp\n"
          ]
        }
      ],
      "source": [
        "## First screening of the catalog for the removal of the AFTERSHOCK\n",
        "# Forward screening\n",
        "\n",
        "MAGNITUDE_ALL = df['MwDef'].values\n",
        "LONG_ALL = df['LonDef'].values\n",
        "LAT_ALL = df['LatDef'].values\n",
        "\n",
        "INDEX_DF = df.index.values\n",
        "\n",
        "Year_all   = df['Year'].values\n",
        "Month_all  = df['Mo'].values\n",
        "Day_all    = df['Da'].values\n",
        "Hour_all   = df['Ho'].values\n",
        "Minute_all = df['Mi'].values\n",
        "Second_all = df['Se'].values\n",
        "\n",
        "Year_all = Year_all.astype('int')\n",
        "Month_all = Month_all.astype('int')\n",
        "Day_all = Day_all.astype('int')\n",
        "Hour_all = Hour_all.astype('int')\n",
        "Minute_all = Minute_all.astype('int')\n",
        "Second_all = Second_all.astype('int')\n",
        "\n",
        "ind_catalogue_aftershock = []\n",
        "\n",
        "# CONVERSION OF ALL DATES TO NUMBERS\n",
        "DateNumber_all = [date_number(Year_all[j],Month_all[j],Day_all[j],Hour_all[j],Minute_all[j],Second_all[j]) for j in range(len(df))]\n",
        "\n",
        "for i in range(len(df)):\n",
        "    # Extraction of the magnitude from the catalog\n",
        "\n",
        "    Mw = MAGNITUDE_ALL[i]\n",
        "\n",
        "    # Extraction of epicenter location from the catalog\n",
        "    LONG = LONG_ALL[i]\n",
        "    LAT  = LAT_ALL[i]\n",
        "    \n",
        "    # DEFINITION OF THE TIME WINDOW ACCORDING TO 3 DIFFERENT FORMULATIONS\n",
        "    # The final time windows, in days, will be average of the three.\n",
        "    if Mw >= 6.5:\n",
        "        # Formulation according to (Gardner and Knopoff 1974)\n",
        "        DT1 = 10**(0.032*Mw + 2.7389) # DAYS\n",
        "        # Formulation according to (Gruenthal)\n",
        "        DT2=abs(np.exp(-3.95+(0.62+17.32*Mw)**2)) # DAYS\n",
        "    else:\n",
        "        # Formulation according to (Gardner and Knopoff 1974)\n",
        "        DT1 = 10**(0.5409*Mw - 0.547) # DAYS\n",
        "        # Formulation according to (Gruenthal)\n",
        "        DT2=10**(2.8+0.024*Mw) # DAYS\n",
        "\n",
        "    # Formulation according to (Uhrhammer 1986)\n",
        "    DT3 = np.exp(-2.87+1.235*Mw)\n",
        "    \n",
        "    # Average of the three different formluations\n",
        "    DT = [DT1, DT2, DT3]\n",
        "    DT = [0 if dt == np.inf else dt for dt in DT]\n",
        "    DT = max(DT) # DAYS\n",
        "    \n",
        "    # DEFINITION OF THE SPATIAL WINDOW ACCORDING TO 3 DIFFERENT FORMULATIONS\n",
        "    # The final time windows, in days, will be average of the three.\n",
        "    # Formulation according to (Gardner and Knopoff 1974)\n",
        "    R1 = 10**(0.1238*Mw+0.983) # km\n",
        "    # Formulation according to (Gruenthal)\n",
        "    R2 = np.exp(1.77+(0.037+1.02*Mw)**2) # km\n",
        "    # Formulation according to (Uhrhammer 1986)\n",
        "    R3 = np.exp(-1.024+0.804*Mw) # km\n",
        "    \n",
        "    # Average of the three different formluations\n",
        "    R = [R1, R2, R3]\n",
        "    R = [0 if r > 1000 else r for r in R]\n",
        "    R = max(R) # km\n",
        "    \n",
        "    # CALCULATION OF THE DISTANCE BETWEEN THE CURRENT EPICENTER AND ALL THE\n",
        "    # OTHER EPICENTERS OF THE OTHER EVENTS\n",
        "    DISTANCES_i = DISTANCES[i]\n",
        "\n",
        "    Year   = Year_all[i]\n",
        "    Month  = Month_all[i]\n",
        "    Day    = Day_all[i]\n",
        "    Hour   = Hour_all[i]\n",
        "    Minute = Minute_all[i]\n",
        "    Second = Second_all[i]\n",
        "    \n",
        "    # CALCULATION OF THE CURRENT DAY + TIME WINDWOW\n",
        "    y=np.floor(DT/365)\n",
        "    m=np.floor(((DT/365-y)*365)/30)\n",
        "    d=(((DT/365-y)*365)/30-m)*30\n",
        "\n",
        "    months_days = [31 if i not in [3, 5, 8, 10] else 30 for i in range(12)]\n",
        "    months_days[1] = 29 if is_leap_year(int(Year+y)) else 28\n",
        "\n",
        "    while int(Month+m) > 12 or int(Day+d) > months_days[int(Month+m)-1]:\n",
        "        \n",
        "        if int(Month+m) > 12:\n",
        "            y += 1\n",
        "            m -= 12\n",
        "            months_days[1] = 29 if is_leap_year(int(Year+y)) else 28\n",
        "\n",
        "        if int(Day+d) > months_days[int(Month+m)-1]:\n",
        "            d -=  months_days[int(Month+m)-1]\n",
        "            m += 1\n",
        "\n",
        "    UpperBoundTime = date_number(int(Year+y),int(Month+m),int(Day+d),Hour,Minute,Second)\n",
        "    \n",
        "    # IDENTIFICATION OF THE EVENTS FALLING IN THE TIME-SPACE WINDOW HAVING\n",
        "    # A MAGNITUDE LOWER OR EQUAL THAN THE CURRENT VALUE Mw\n",
        "    index = []\n",
        "    [index.append(idx) for idx in range(i+1,len(df)) if DateNumber_all[idx]>DateNumber_all[i] and DateNumber_all[idx]<=UpperBoundTime and MAGNITUDE_ALL[idx]<Mw and DISTANCES_i[idx]<=R]\n",
        "    \n",
        "    # ASSEMBLING THE INDEXES IN A SINGLE MATRIX\n",
        "    [ind_catalogue_aftershock.append(idx) for idx in index if index != []]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MSUCkbBkK6m",
        "outputId": "507b0e8c-88b6-4e22-e5d3-32d070595914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 111  127  128 ... 4855 4856 4859]\n"
          ]
        }
      ],
      "source": [
        "# REMOVAL OF REPETING INDEXES\n",
        "ind_catalogue_aftershock_unique = np.unique(ind_catalogue_aftershock)\n",
        "print(INDEX_DF[ind_catalogue_aftershock_unique])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWValyOZ7hps",
        "outputId": "8f862685-aa83-4ba6-8070-0054cf0de1c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aftershock removal: 1889 events removed from the catalogue\n"
          ]
        }
      ],
      "source": [
        "print(f\"Aftershock removal: {ind_catalogue_aftershock_unique.size} events removed from the catalogue\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RQk3JjRrlSQA"
      },
      "outputs": [],
      "source": [
        "# REMOVAL OF AFTERSHOCK FROM THE CATALOG\n",
        "df_UPD = deepcopy(df)\n",
        "df_UPD.drop(index=INDEX_DF[ind_catalogue_aftershock_unique],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvmxXCzxAz-e",
        "outputId": "39646175-e803-426c-e2de-40d07bd32479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2708\n"
          ]
        }
      ],
      "source": [
        "print(len(df_UPD))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IstDJK80yqGE",
        "outputId": "6a18bddb-cac3-495f-ae94-3a9d9f8e1177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2708\n"
          ]
        }
      ],
      "source": [
        "DISTANCES_UPD = [DISTANCES[k] for k in range(len(df)-1,-1,-1) if k not in ind_catalogue_aftershock_unique]\n",
        "print(len(DISTANCES_UPD))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzO3kNuX8aD_",
        "outputId": "70a79ae7-0536-437a-b239-3d7acc75fa53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: RuntimeWarning: overflow encountered in exp\n"
          ]
        }
      ],
      "source": [
        "#%% Second screening of the catalog for the removal of the FORESHOCK\n",
        "#% Backward screening\n",
        "\n",
        "MAGNITUDE_ALL = df_UPD['MwDef'].values\n",
        "LONG_ALL = df_UPD['LonDef'].values\n",
        "LAT_ALL = df_UPD['LatDef'].values\n",
        "\n",
        "INDEX_DF_UPD = df_UPD.index.values\n",
        "\n",
        "Year_all   = df_UPD['Year'].values\n",
        "Month_all  = df_UPD['Mo'].values\n",
        "Day_all    = df_UPD['Da'].values\n",
        "Hour_all   = df_UPD['Ho'].values\n",
        "Minute_all = df_UPD['Mi'].values\n",
        "Second_all = df_UPD['Se'].values\n",
        "\n",
        "Year_all = Year_all.astype('int')\n",
        "Month_all = Month_all.astype('int')\n",
        "Day_all = Day_all.astype('int')\n",
        "Hour_all = Hour_all.astype('int')\n",
        "Minute_all = Minute_all.astype('int')\n",
        "Second_all = Second_all.astype('int')\n",
        "\n",
        "ind_catalogue_foreshock = []\n",
        "\n",
        "# CONVERSION OF ALL DATES TO NUMBERS\n",
        "DateNumber_all = [date_number(Year_all[j],Month_all[j],Day_all[j],Hour_all[j],Minute_all[j],Second_all[j]) for j in range(len(df_UPD))]\n",
        "\n",
        "for i in range(len(df_UPD)-1,-1,-1):\n",
        "    # Extraction of the magnitude from the catalog\n",
        "    Mw = MAGNITUDE_ALL[i]\n",
        "\n",
        "    # Extraction of epicenter location from the catalog\n",
        "    LONG = LONG_ALL[i]\n",
        "    LAT  = LAT_ALL[i]\n",
        "    \n",
        "    # DEFINITION OF THE TIME WINDOW ACCORDING TO 3 DIFFERENT FORMULATIONS\n",
        "    # The final time windows, in days, will be average of the three.\n",
        "    if Mw >= 6.5:\n",
        "        # Formulation according to (Gardner and Knopoff 1974)\n",
        "        DT1 = 10**(0.032*Mw + 2.7389)  # DAYS\n",
        "        # Formulation according to (Gruenthal)\n",
        "        DT2=abs(np.exp(-3.95+(0.62+17.32*Mw)**2)) # DAYS\n",
        "    else:\n",
        "        # Formulation according to (Gardner and Knopoff 1974)\n",
        "        DT1 = 10**(0.5409*Mw - 0.547) # DAYS\n",
        "        # Formulation according to (Gruenthal)\n",
        "        DT2=10**(2.8+0.024*Mw) # DAYS\n",
        "\n",
        "    # Formulation according to (Uhrhammer 1986)\n",
        "    DT3 = np.exp(-2.87+1.235*Mw)\n",
        "    \n",
        "    # Average of the three different formluations\n",
        "    DT = [DT1, DT2, DT3]\n",
        "    DT = [0 if dt == np.inf else dt for dt in DT]\n",
        "    DT = max(DT) # DAYS\n",
        "    \n",
        "    # DEFINITION OF THE SPATIAL WINDOW ACCORDING TO 3 DIFFERENT FORMULATIONS\n",
        "    # The final time windows, in days, will be average of the three.\n",
        "    # Formulation according to (Gardner and Knopoff 1974)\n",
        "    R1 = 10**(0.1238*Mw+0.983) # km\n",
        "    # Formulation according to (Gruenthal)\n",
        "    R2 = np.exp(1.77+(0.037+1.02*Mw)**2) # km\n",
        "    # Formulation according to (Uhrhammer 1986)\n",
        "    R3 = np.exp(-1.024+0.804*Mw) # km\n",
        "    \n",
        "    # Average of the three different formluations\n",
        "    R = [R1, R2, R3]\n",
        "    R = [0 if r > 1000 else r for r in R]\n",
        "    R = max(R) # km\n",
        "    \n",
        "    # CALCULATION OF THE DISTANCE BETWEEN THE CURRENT EPICENTER AND ALL THE\n",
        "    # OTHER EPICENTERS OF THE OTHER EVENTS\n",
        "    DISTANCES_i = DISTANCES_UPD[i]\n",
        "\n",
        "    Year   = Year_all[i]\n",
        "    Month  = Month_all[i]\n",
        "    Day    = Day_all[i]\n",
        "    Hour   = Hour_all[i]\n",
        "    Minute = Minute_all[i]\n",
        "    Second = Second_all[i]\n",
        "\n",
        "    # CALCULATION OF THE CURRENT DAY + TIME WINDWOW\n",
        "    y=np.floor(DT/365)\n",
        "    m=np.floor(((DT/365-y)*365)/30)\n",
        "    d=(((DT/365-y)*365)/30-m)*30\n",
        "\n",
        "    months_days = [31 if i not in [3, 5, 8, 10] else 30 for i in range(12)]\n",
        "    months_days[1] = 29 if is_leap_year(int(Year+y)) else 28\n",
        "\n",
        "    while int(Month+m) > 12 or int(Day+d) > months_days[int(Month+m)-1]:\n",
        "        \n",
        "        if int(Month+m) > 12:\n",
        "            y += 1\n",
        "            m -= 12\n",
        "            months_days[1] = 29 if is_leap_year(int(Year+y)) else 28\n",
        "\n",
        "        if int(Day+d) > months_days[int(Month+m)-1]:\n",
        "            d -=  months_days[int(Month+m)-1]\n",
        "            m += 1\n",
        "\n",
        "    UpperBoundTime = date_number(int(Year+y),int(Month+m),int(Day+d),Hour,Minute,Second)\n",
        "    \n",
        "    # IDENTIFICATION OF THE EVENTS FALLING IN THE TIME-SPACE WINDOW HAVING\n",
        "    # A MAGNITUDE LOWER OR EQUAL THAN THE CURRENT VALUE Mw\n",
        "  \n",
        "    index = list()\n",
        "    [index.append(idx) for idx in range(i-1,-1,-1) if DateNumber_all[idx]>DateNumber_all[i] and DateNumber_all[idx]<=UpperBoundTime and MAGNITUDE_ALL[idx]<Mw and DISTANCES_i[idx]<=R]\n",
        "    \n",
        "    # ASSEMBLING THE INDEXES IN A SINGLE MATRIX\n",
        "    [ind_catalogue_foreshock.append(idx) for idx in index if index != []]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGeXPxme6Avs",
        "outputId": "b141818b-96a7-41d5-cd4c-81e1657954c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Foreshock removal: 0 events removed from the catalogue\n"
          ]
        }
      ],
      "source": [
        "# REMOVAL OF REPETING INDEXES\n",
        "ind_catalogue_foreshock_unique = np.unique(ind_catalogue_foreshock)\n",
        "print(f\"Foreshock removal: {ind_catalogue_foreshock_unique.size} events removed from the catalogue\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Oy3pMlE86Cq0"
      },
      "outputs": [],
      "source": [
        "# REMOVAL OF FORESHOCK FROM THE CATALOG\n",
        "df_UPD2 = deepcopy(df_UPD)\n",
        "if ind_catalogue_foreshock_unique.size > 0:\n",
        "    df_UPD2.drop(index=INDEX_DF_UPD[ind_catalogue_foreshock_unique],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtqLOTINAsMe",
        "outputId": "1d03ca80-86f7-4a64-a9fa-f76214b3af29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2708\n"
          ]
        }
      ],
      "source": [
        "print(len(df_UPD2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4mNiW_0c61i",
        "outputId": "93d54f93-daa0-4f07-9e03-767c0fdaee0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Year   Mo    Da   Ho  ...  DepDef  MwDef             X             Y\n",
            "Index                        ...                                           \n",
            "2      1019  4.0   1.0  0.0  ...     NaN   4.63  9.850866e+05  4.569418e+06\n",
            "3      1044  4.0  19.0  9.0  ...     NaN   4.63  9.850866e+05  4.569418e+06\n",
            "5      1065  3.0  27.0  0.0  ...     NaN   5.10  5.952487e+05  5.043553e+06\n",
            "7      1087  9.0  10.0  0.0  ...     NaN   4.86  1.160782e+06  4.583025e+06\n",
            "8      1091  1.0  27.0  0.0  ...     NaN   5.10  7.884312e+05  4.644411e+06\n",
            "\n",
            "[5 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "df_UPD2.index.names = ['Index']\n",
        "print(df_UPD2.head())\n",
        "df_UPD2.to_excel(output_catalogue_path, header=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPLS9auV5BzZnnMrNahomXf",
      "collapsed_sections": [],
      "include_colab_link": true,
      "mount_file_id": "https://github.com/valebl/SSZ_Clustering/blob/main/Catalogue_declustering.ipynb",
      "name": "Catalogue_declustering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
